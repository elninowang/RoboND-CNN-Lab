{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Image Classification 图像分类\n",
    "\n",
    "In this lab, you'll classify images from the [Fashion-MNIST dataset](https://github.com/zalandoresearch/fashion-mnist#get-the-data).  The dataset consists of different types of clothing items such as shirts, trousers, sneakers etc. You'll preprocess the images, then train a convolutional neural network on all the samples. The images need to be normalized and the labels need to be one-hot encoded.  You'll get to apply what you learned and build a model with convolutional, max pooling, dropout, and fully connected layers.  At the end, you'll get to see your neural network's predictions on the sample images.\n",
    "\n",
    "在本实验中，您将对[Fashion-MNIST数据集](https://github.com/zalandoresearch/fashion-mnist#get-the-data) 中的图像进行分类。 数据集由不同类型的服装项目组成，如衬衫，长裤，运动鞋等。您将对图像进行预处理，然后在所有样品上训练卷积神经网络。 图像需要归一化，标签需要进行一次热编码。 您将获得应用您学到的内容，并构建一个具有卷积，最大池，退出和完全连接的图层的模型。 最后，您将看到您的神经网络对样本图像的预测。\n",
    "\n",
    "\n",
    "## Get the Data 获取数据\n",
    "\n",
    "We have provided you with a pickle file for the dataset available in the GitHub repo. We have provided with a script - helper.py, which extracts the dataset for you when the corresponding functions are called.\n",
    "\n",
    "我们为您提供了GitHub回购中提供的数据集的pickle文件。 我们提供了一个脚本 - helper.py，它在调用相应的函数时提取数据集。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Data 浏览数据\n",
    "\n",
    "The Fashion-MNIST dataset consists of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from the following 10 classes:\n",
    "\n",
    "时尚MNIST数据集由6万个示例的培训集和10,000个示例的测试集组成。 每个示例是一个28x28灰度图像，与以下10个类别的标签相关联：\n",
    "\n",
    "* T-shirt/top  T恤衫/上衣\n",
    "* Trouser 裤\n",
    "* Pullover 套衫\n",
    "* Dress 衣服\n",
    "* Coat 外套\n",
    "* Sandal 凉鞋\n",
    "* Shirt 衬衫\n",
    "* Sneaker 运动鞋\n",
    "* Bag 袋\n",
    "* Ankle boot 脚踝靴\n",
    "\n",
    "Understanding a dataset is part of making predictions on the data.  Play around with the code cell below by changing the `sample_id`. The `sample_id` is the id for a image and label pair in the dataset.\n",
    "\n",
    "了解数据集是对数据进行预测的一部分。 通过更改`sample_id`，在下面的代码单元中播放。 `sample_id`是数据集中图像和标签对的ID。\n",
    "\n",
    "Ask yourself \"What are all possible labels?\", \"What is the range of values for the image data?\", \"Are the labels in order or random?\".  Answers to questions like these will help you preprocess the data and end up with better predictions.\n",
    "\n",
    "问自己“所有可能的标签是什么？”，“图像数据的值范围是多少？”，“标签是按顺序还是随机？ 对这些问题的回答将有助于您预处理数据，并最终获得更好的预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 60000\n",
      "Label Counts: {0: 6000, 1: 6000, 2: 6000, 3: 6000, 4: 6000, 5: 6000, 6: 6000, 7: 6000, 8: 6000, 9: 6000}\n",
      "First 20 Labels: [9 0 0 3 0 2 7 2 5 5 0 9 5 5 7 9 1 0 6 4]\n",
      "\n",
      "Example of Image 7:\n",
      "Image - Min Value: 0 Max Value: 255\n",
      "Image - Shape: (28, 28, 1)\n",
      "Label - Label Id: 2 Name: pullover\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/oeJ7AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2192a2ccc18>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "\n",
    "filename = \"fashion-mnist.p\"\n",
    "\n",
    "# Explore the dataset\n",
    "sample_id = 7\n",
    "helper.display_stats(filename, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Preprocess Functions 实现预处理功能\n",
    "\n",
    "### Normalize 归一化\n",
    "\n",
    "In the cell below, implement the `normalize` function to take in image data, `x`, and return it as a normalized Numpy array. The values should be in the range of 0 to 1, inclusive.  The return object should be the same shape as `x`.\n",
    "\n",
    "在下面的单元格中，实现`normalize`函数来获取图像数据`x`，并将其作为归一化的Numpy数组返回。 值应在0到1的范围内。 返回对象的形状应与“x”相同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import problem_unittests as tests\n",
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (28, 28, 1)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encode 独热编码\n",
    "\n",
    "Just like the previous code cell, you'll be implementing a function for preprocessing.  This time, you'll implement the `one_hot_encode` function. The input, `x`, are a list of labels.  Implement the function to return the list of labels as One-Hot encoded Numpy array.  The possible values for labels are 0 to 9. The one-hot encoding function should return the same encoding for each value between each call to `one_hot_encode`.  Make sure to save the map of encodings outside the function.\n",
    "\n",
    "就像以前的代码单元一样，你将会实现一个预处理功能。 这一次，你将实现 `one_hot_encode` 功能。 输入 `x`是标签列表。 实现函数将标签列表返回为一个热编码的Numpy数组。 标签的可能值为0到9.单热编码功能应在每个调用 `one_hot_encode` 之间返回相同的编码值。 确保将函数的地图保存在函数外。\n",
    "\n",
    "Hint: Don't reinvent the wheel. You have multiple ways to attempt this: Numpy, TF, or even sklearn's preprocessing package.\n",
    "\n",
    "提示：不要重新发明轮子。 您有多种尝试方法：Numpy，TF或甚至sklearn的预处理软件包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomize Data 随机化数据\n",
    "\n",
    "As you saw from exploring the data above, the order of the samples are randomized.  It doesn't hurt to randomize it again, but you don't need to for this dataset.\n",
    "\n",
    "从上面的数据可以看出，样本的顺序是随机的。 再次对它进行随机化并不会伤害，但是您不需要为此数据集。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess all the data and save it 预处理所有数据并保存\n",
    "\n",
    "Running the code cell below will preprocess all the Fashion-MNIST data and save it to file. The code below also uses 10% of the training data for validation.\n",
    "\n",
    "运行下面的代码单元将预处理所有的Fashion-MNIST数据并保存到文件。 下面的代码也使用10％的训练数据进行验证。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(filename, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Point 检查点\n",
    "\n",
    "This is your first checkpoint.  If you ever decide to come back to this notebook or have to restart the notebook, you can start from here.  The preprocessed data has been saved to disk.\n",
    "\n",
    "这是你的第一个检查点。 如果您决定回到笔记本电脑或重新启动笔记本电脑，您可以从这里开始。 预处理数据已保存到磁盘。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the network 构建网络\n",
    "\n",
    "For the neural network, you'll build each layer into a function.  Most of the code you've seen has been outside of functions. To test your code more thoroughly, we require that you put each layer in a function.  This allows us to give you better feedback and test for simple mistakes using our unittests.\n",
    "\n",
    "对于神经网络，您将构建每个层的功能。 你看到的大部分代码都不在函数之内。 为了更彻底地测试你的代码，我们要求你把每个层都放在一个函数中。 这使我们能够使用我们的单位测试为您提供更好的反馈和测试简单的错误。\n",
    "\n",
    "Let's begin! 让我们开始\n",
    "\n",
    "### Input 输入\n",
    "\n",
    "The neural network needs to read the image data, one-hot encoded labels, and dropout keep probability. Implement the following functions\n",
    "\n",
    "神经网络需要读取图像数据，单热编码标签和丢弃保持概率。 实现以下功能\n",
    "\n",
    "* Implement `neural_net_image_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `image_shape` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"x\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_label_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `n_classes` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"y\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_keep_prob_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) for dropout keep probability.\n",
    " * Name the TensorFlow placeholder \"keep_prob\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "\n",
    "These names will be used at the end of the lab to load your saved model.\n",
    "\n",
    "这些名称将在实验室结束时使用，以加载您保存的模型。\n",
    "\n",
    "Note: `None` for shapes in TensorFlow allow for a dynamic size.\n",
    "\n",
    "注意：TensorFlow中的 `None` 形状允许动态大小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution and Max Pooling Layer\n",
    "\n",
    "### 卷积和最大池集合\n",
    "\n",
    "Convolution layers have a lot of success with images. For this code cell, you should implement the function `conv2d_maxpool` to apply convolution then max pooling:\n",
    "\n",
    "卷积层在图像上取得了很大的成功。 对于这个代码单元格，你应该实现函数 `conv2d_maxpool` 来应用卷积然后应用最大池：\n",
    "\n",
    "* Create the weight and bias using `conv_ksize`, `conv_num_outputs` and the shape of `x_tensor`.\n",
    "* Apply a convolution to `x_tensor` using weight and `conv_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "* Add bias\n",
    "* Add a nonlinear activation to the convolution.\n",
    "* Apply Max Pooling using `pool_ksize` and `pool_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    " \n",
    "* 使用 `conv_ksize`，`conv_num_outputs`和 `x_tensor`的形状创建权重和偏差。\n",
    "* 使用weight和 `conv_strides` 对 `x_tensor` 应用卷积。\n",
    " * 我们建议您使用相同的填充，但欢迎使用任何填充。\n",
    "* 增加偏见\n",
    "* 向卷积添加非线性激活。\n",
    "* 使用 `pool_ksize` 和 `pool_strides` 应用最大池。\n",
    " * 我们建议您使用相同的填充，但欢迎使用任何填充。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten Layer 平铺层\n",
    "\n",
    "Implement the `flatten` function to change the dimension of `x_tensor` from a 4-D tensor to a 2-D tensor.  The output should be the shape (*Batch Size*, *Flattened Image Size*). \n",
    "\n",
    "实现 `flatten` 功能，将 `x_tensor` 的尺寸从4-D张量更改为2-D张量。 输出应为形状（*Batch Size*，*Flattened Image Size*）。\n",
    "\n",
    "Shortcut Option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer which help with some high-level features. For more of a challenge, only use other TensorFlow packages.\n",
    "\n",
    "快捷方式选项：您可以使用 [TensorFlow层](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow层（contrib）](https://www.tensorflow.org/api_guides/python/contrib.layers) 这个层的软件包，有助于一些高级功能。 对于更多的挑战，只能使用其他TensorFlow软件包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully-Connected Layer 全连接层\n",
    "\n",
    "Implement the `fully_conn` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). \n",
    "\n",
    "实现`fully_conn`函数，使用shape (*Batch Size*，*num_outputs*) 将完全连接的层应用于`x_tensor`。\n",
    "\n",
    "Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages.\n",
    "\n",
    "快捷方式选项：您可以使用 [TensorFlow层](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow层(contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包。 对于更多的挑战，只能使用其他TensorFlow软件包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Layer 输出层\n",
    "\n",
    "Implement the `output` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). \n",
    "\n",
    "实现`output`函数，使用形状 (*Batch Size*，*num_outputs*) 将完全连接的图层应用于 `x_tensor`。\n",
    "\n",
    "Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages.\n",
    "\n",
    "快捷方式选项：您可以使用[TensorFlow层](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow层(contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包。 对于更多的挑战，只能使用其他TensorFlow软件包。\n",
    "\n",
    "**Note:** Activation, softmax, or cross entropy should **not** be applied to this.\n",
    "\n",
    "**注意：** 激活，softmax或交叉熵应该 **不** 适用于此。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Convolutional Model 创建卷积模型\n",
    "\n",
    "Implement the function `conv_net` to create a convolutional neural network model. The function takes in a batch of images, `x`, and outputs logits.  Use the layers you created above to create this model:\n",
    "\n",
    "实现函数 `conv_net` 来创建卷积神经网络模型。 该函数接收一批图像`x`，并输出逻辑。 使用上面创建的图层创建此模型：\n",
    "\n",
    "* Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "* Apply a Flatten Layer\n",
    "* Apply 1, 2, or 3 Fully Connected Layers\n",
    "* Apply an Output Layer\n",
    "* Return the output\n",
    "* Apply [TensorFlow's Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) to one or more layers in the model using `keep_prob`.\n",
    "\n",
    "* 应用1，2或3卷积和最大池层\n",
    "* 应用平铺层\n",
    "* 应用1,2或3个完全连接的图层\n",
    "* 应用输出层\n",
    "* 返回输出\n",
    "* 使用`keep_prob`将 [TensorFlow's Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) 应用于模型中的一个或多个图层。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    \n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    \n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    \n",
    "    # TODO: return output\n",
    "    return None\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((28, 28, 1))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Neural Network 训练神经网络\n",
    "\n",
    "### Single Optimization 简单的优化器\n",
    "\n",
    "Implement the function `train_neural_network` to do a single optimization.  The optimization should use `optimizer` to optimize in `session` with a `feed_dict` of the following:\n",
    "* `x` for image input\n",
    "* `y` for labels\n",
    "* `keep_prob` for keep probability for dropout\n",
    "\n",
    "This function will be called for each batch, so `tf.global_variables_initializer()` has already been called.\n",
    "\n",
    "Note: Nothing needs to be returned. This function is only optimizing the neural network.\n",
    "\n",
    "实现函数`train_neural_network`进行一个优化。 优化应该使用`optimizer`来在`session`中用`feed_dict`进行优化：\n",
    "* `x`用于图像输入\n",
    "* `y`标签\n",
    "* `keep_prob`为了保留遗漏的概率\n",
    "\n",
    "这个函数将被调用每个批处理，所以`tf.global_variables_initializer（）`已经被调用了。\n",
    "\n",
    "注意：没有什么需要返回。 这个功能只是优化神经网络。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "\n",
    "    session.run(optimizer, feed_dict={x: feature_batch, y: label_batch, keep_prob: keep_probability})\n",
    "    \n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Stats 显示状态\n",
    "\n",
    "Implement the function `print_stats` to print loss and validation accuracy.  Use the global variables `valid_features` and `valid_labels` to calculate validation accuracy.  Use a keep probability of `1.0` to calculate the loss and validation accuracy.\n",
    "\n",
    "实现函数 `print_stats `来打印丢失和验证的准确性。 使用全局变量 `valid_features `和 `valid_labels `来计算验证精度。 使用 `1.0 ` 的保持概率来计算损失和验证准确性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    l = session.run(cost, feed_dict={x: feature_batch, y: label_batch, keep_prob: 1.0})\n",
    "    validation_accuracy = session.run(accuracy, feed_dict={x: valid_features, y: valid_labels, keep_prob: 1.0})\n",
    "    \n",
    "    print(\"The loss is: {0}, and the Validation Accuracy is: {1}\".format(l, validation_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters 超参数\n",
    "Tune the following parameters:\n",
    "* Set `epochs` to the number of iterations until the network stops learning or start overfitting\n",
    "* Set `batch_size` to the highest number that your machine has memory for.  Most people set them to common sizes of memory:\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* Set `keep_probability` to the probability of keeping a node using dropout\n",
    "\n",
    "调整以下参数：\n",
    "* 将`epochs`设置为迭代次数，直到网络停止学习或开始过度拟合\n",
    "* 将`batch_size`设置为您的计算机具有内存的最高数字。 大多数人将它们设置为常规大小的内存：\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* 将`keep_probability`设置为保持节点使用退出的概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 2\n",
    "batch_size = 64\n",
    "keep_probability = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model 训练模型\n",
    "\n",
    "Now that you have your model built and your hyperparameters defined, let's train it!\n",
    "\n",
    "现在你已经建立了你的模型并定义了你的超参数，让我们来训练吧！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}:  '.format(epoch + 1), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint 检查点\n",
    "\n",
    "The model has been saved to disk. \n",
    "\n",
    "该模型已保存到磁盘。\n",
    "\n",
    "## Test Model 测试模型\n",
    "\n",
    "Test your model against the test dataset.  This will be your final accuracy. You should have an accuracy greater than 50%. If you don't, keep tweaking the model architecture and parameters.\n",
    "\n",
    "根据测试数据集测试您的模型。 这将是您的最终准确性。 你的准确度应该在50％以上。 如果没有，请继续调整模型体系结构和参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_test.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "    \n",
    "    config = tf.ConfigProto(device_count = {'GPU': 0})\n",
    "\n",
    "    with tf.Session(config=config, graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for test_feature_batch, test_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: test_feature_batch, loaded_y: test_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
